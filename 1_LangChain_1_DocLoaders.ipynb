{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW0QCcjBH3PC"
      },
      "outputs": [],
      "source": [
        "!pip install -r sample_data/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Text loader\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "txt_loader = TextLoader('sample_data/speech.txt')\n",
        "txt_documents = txt_loader.load()\n",
        "txt_documents"
      ],
      "metadata": {
        "id": "-SKOdZe3I871"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##PDF loader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "pdf_loader = PyPDFLoader(\"sample_data/attention.pdf\")\n",
        "pdf_documents= pdf_loader.load()\n",
        "pdf_documents"
      ],
      "metadata": {
        "id": "rV8-z5t1MZUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Web based loader\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "import bs4\n",
        "web_loader = WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "                           bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
        "                                   class_=(\"post-title\",\"post-content\",\"post-header\")\n",
        "                               ))\n",
        "                           )\n",
        "web_documents = web_loader.load()\n",
        "web_documents"
      ],
      "metadata": {
        "id": "HvObiwEMNz_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "f3l6gD2EWQXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Arxiv Loader\n",
        "from langchain_community.document_loaders import ArxivLoader\n",
        "\n",
        "# Supports all arguments of `ArxivAPIWrapper`\n",
        "arxiv_loader = ArxivLoader(\n",
        "    query=\"reasoning\",\n",
        "    load_max_docs=2,\n",
        "    # doc_content_chars_max=1000,\n",
        "    # load_all_available_meta=False,\n",
        "    # ...\n",
        ")\n",
        "arxiv_documents = arxiv_loader.load()\n",
        "arxiv_documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Fu5uauPpSXu6",
        "outputId": "ddc5e935-8e65-4a3d-8bbd-b07e328bbb4b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'Published': '2024-10-16', 'Title': 'Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models', 'Authors': 'Linhao Luo, Zicheng Zhao, Chen Gong, Gholamreza Haffari, Shirui Pan', 'Summary': 'Large language models (LLMs) have demonstrated impressive reasoning\\nabilities, but they still struggle with faithful reasoning due to knowledge\\ngaps and hallucinations. To address these issues, knowledge graphs (KGs) have\\nbeen utilized to enhance LLM reasoning through their structured knowledge.\\nHowever, existing KG-enhanced methods, either retrieval-based or agent-based,\\nencounter difficulties in accurately retrieving knowledge and efficiently\\ntraversing KGs at scale. In this work, we introduce graph-constrained reasoning\\n(GCR), a novel framework that bridges structured knowledge in KGs with\\nunstructured reasoning in LLMs. To eliminate hallucinations, GCR ensures\\nfaithful KG-grounded reasoning by integrating KG structure into the LLM\\ndecoding process through KG-Trie, a trie-based index that encodes KG reasoning\\npaths. KG-Trie constrains the decoding process, allowing LLMs to directly\\nreason on graphs and generate faithful reasoning paths grounded in KGs.\\nAdditionally, GCR leverages a lightweight KG-specialized LLM for\\ngraph-constrained reasoning alongside a powerful general LLM for inductive\\nreasoning over multiple reasoning paths, resulting in accurate reasoning with\\nzero reasoning hallucination. Extensive experiments on several KGQA benchmarks\\ndemonstrate that GCR achieves state-of-the-art performance and exhibits strong\\nzero-shot generalizability to unseen KGs without additional training.'}, page_content='GRAPH-CONSTRAINED REASONING: FAITHFUL REA-\\nSONING ON KNOWLEDGE GRAPHS WITH LARGE LAN-\\nGUAGE MODELS\\nLinhao Luo1∗, Zicheng Zhao2∗, Chen Gong2, Gholamreza Haffari1, Shirui Pan3†\\n1Monash University 2Nanjing University of Science and Technology 3Griffith University\\n{Linhao.Luo,Gholamreza.Haffari}@monash.edu\\n{zicheng.zhao,chen.gong}@njust.edu.cn, s.pan@griffith.edu.au\\nABSTRACT\\nLarge language models (LLMs) have demonstrated impressive reasoning abilities,\\nbut they still struggle with faithful reasoning due to knowledge gaps and halluci-\\nnations. To address these issues, knowledge graphs (KGs) have been utilized to\\nenhance LLM reasoning through their structured knowledge. However, existing\\nKG-enhanced methods, either retrieval-based or agent-based, encounter difficul-\\nties in accurately retrieving knowledge and efficiently traversing KGs at scale.\\nIn this work, we introduce graph-constrained reasoning (GCR), a novel frame-\\nwork that bridges structured knowledge in KGs with unstructured reasoning in\\nLLMs. To eliminate hallucinations, GCR ensures faithful KG-grounded reason-\\ning by integrating KG structure into the LLM decoding process through KG-Trie,\\na trie-based index that encodes KG reasoning paths. KG-Trie constrains the de-\\ncoding process, allowing LLMs to directly reason on graphs and generate faith-\\nful reasoning paths grounded in KGs. Additionally, GCR leverages a lightweight\\nKG-specialized LLM for graph-constrained reasoning alongside a powerful gen-\\neral LLM for inductive reasoning over multiple reasoning paths, resulting in ac-\\ncurate reasoning with zero reasoning hallucination. Extensive experiments on\\nseveral KGQA benchmarks demonstrate that GCR achieves state-of-the-art per-\\nformance and exhibits strong zero-shot generalizability to unseen KGs without\\nadditional training. Code is available at https://github.com/RManLuo/\\ngraph-constrained-reasoning.\\n1\\nINTRODUCTION\\nLarge language models (LLMs) have shown impressive reasoning abilities in handling complex\\ntasks (Qiao et al., 2023; Huang & Chang, 2023), marking a significant leap that bridges the gap\\nbetween human and machine intelligence. However, LLMs still struggle with conducting faithful\\nreasoning due to issues of lack of knowledge and hallucination (Huang et al., 2024; Wang et al.,\\n2023). These issues result in factual errors and flawed reasoning processes (Nguyen et al., 2024),\\nwhich greatly undermine the reliability of LLMs in real-world applications.\\nTo address these issues, many studies utilize knowledge graphs (KGs), which encapsulate extensive\\nfactual information in a structured format, to improve the reasoning abilities of LLMs (Pan et al.,\\n2024; Luo et al., 2024). Nevertheless, because of the unstructured nature of LLMs, directly applying\\nthem to reason on KGs is challenging.\\nExisting KG-enhanced LLM reasoning methods can be roughly categorized into two groups:\\nretrieval-based and agent-based paradigms, as shown in Figure 2 (a) and (b). Retrieval-based meth-\\nods (Li et al., 2023; Yang et al., 2024b; Dehghan et al., 2024) retrieve relevant facts from KGs\\nwith an external retriever and then feed them into the inputs of LLMs for reasoning. Agent-based\\nmethods (Sun et al., 2024; Zhu et al., 2024; Jiang et al., 2024) treat LLMs as agents that iteratively\\ninteract with KGs to find reasoning paths and answers.\\n∗Equal Contribution.\\n†Corresponding author.\\n1\\narXiv:2410.13080v1  [cs.CL]  16 Oct 2024\\n67.0%\\n18.0%\\n15.0%\\nFaithful Reasoning Path\\nInvalid - Format Error\\nInvalid - Relation Error\\nFigure\\n1:\\nAnalysis\\nof reasoning errors in\\nRoG (Luo et al., 2024).\\nDespite their success, retrieval-based methods require additional accurate\\nretrievers, which may not generalize well to unseen questions or account\\nfor the graph structure (Mavromatis & Karypis, 2024). Conversely, agent-\\nbased methods necessitate multiple rounds of interaction between agents\\nand KGs, leading to high computational costs and latency (Dehghan et al.,\\n2024). Furthermore, existing works still suffer from serious hallucination\\nissues (Agrawal et al., 2024). Sui et al. (2024) indicates that RoG (Luo\\net al., 2024), a leading KG-enhanced reasoning method, still experiences\\n33% hallucination errors during reasoning on KGs, as shown in Figure 1.\\nTo this end, we introduce graph-constrained reasoning (GCR), a novel KG-\\nguided reasoning paradigm that connects unstructured reasoning in LLMs\\nwith structured knowledge in KGs, seeking to eliminate hallucinations dur-\\ning reasoning on KGs and ensure faithful reasoning. Inspired by the con-\\ncept that LLMs reason through decoding (Wei et al., 2022), we incorporate\\nthe KG structure into the LLM decoding process. This enables LLMs to directly reason on graphs\\nby generating reliable reasoning paths grounded in KGs that lead to correct answers.\\nIn GCR, we first convert KG into a structured index, KG-Trie, to facilitate efficient reasoning on KG\\nusing LLM. Trie is also known as the prefix tree (Wikipedia contributors, 2024) that compresses a\\nset of strings, which can be used to restrict LLM output tokens to those starting with valid prefixes\\n(De Cao et al., 2022; Xie et al., 2022). KG-Trie encodes the reasoning paths in KGs as formatted\\nstrings to constrain the decoding process of LLMs. Then, we propose graph-constrained decoding\\nthat employs a lightweight KG-specialized LLM to generate multiple KG-grounded reasoning paths\\nand hypothesis answers. With the constraints from KG-Trie, we ensure faithful reasoning while\\nleveraging the strong reasoning capabilities of LLMs to efficiently explore paths on KGs in constant\\ntime. Finally, we input multiple generated reasoning paths and hypothesis answers into a powerful\\ngeneral LLM to utilize its inductive reasoning ability to produce final answers. In this way, GCR\\ncombines the graph reasoning strength of KG-specialized LLMs and the inductive reasoning advan-\\ntage in general LLMs to achieve faithful and accurate reasoning on KGs. The main contributions of\\nthis work are as follows:\\n• We propose a novel framework called graph-constrained reasoning (GCR) that bridges the\\ngap between structured knowledge in KGs and unstructured reasoning in LLMs, allowing\\nfor efficient reasoning on KGs via LLM decoding.\\n• We combine the complementary strengths of a lightweight KG-specialized LLM with a\\npowerful general LLM to enhance reasoning performance by leveraging their respective\\ngraph-based reasoning and inductive reasoning capabilities.\\n• We conduct extensive experiments on several KGQA reasoning benchmarks, demonstrat-\\ning that GCR not only achieves state-of-the-art performance with zero hallucination, but\\nalso shows zero-shot generalizability for reasoning on unseen KGs without additional train-\\ning.\\n2\\nRELATED WORK\\nLLM reasoning. Many studies have been proposed to analyze and improve the reasoning ability\\nof LLMs (Wei et al., 2022; Wang et al., 2024; Yao et al., 2024). To elicit the reasoning ability\\nof LLMs, Chain-of-thought (CoT) reasoning (Wei et al., 2022) prompts the model to generate a\\nchain of reasoning steps in response to a question. Wang et al. (2024) propose a self-consistency\\nmechanism that generates multiple reasoning paths and selects the most consistent answer across\\nthem. The tree-of-thought (Yao et al., 2024) structures reasoning as a branching process, exploring\\nmultiple steps in a tree-like structure to find optimal solutions. Other studies focus on fine-tuning\\nLLMs on various reasoning tasks to improve reasoning abilities (Yu et al., 2022; Hoffman et al.,\\n2024). For instance, OpenAI (2024c) adopts reinforcement learning to train their most advanced\\nLLMs called “OpenAI o1” to perform complex reasoning, which produces a long internal chain of\\nthought before final answers.\\nKG-enhanced LLM reasoning. To mitigate the knowledge gap and hallucination issues in LLM\\nreasoning, research incorporates KGs to enhance LLM reasoning (Pan et al., 2024). KD-CoT (Wang\\n2\\n# Reasoning Path:\\n# Answer:\\nMelania Trump\\nGeneral\\nLLM\\nKG-specialized\\nLLM\\nQ\\nA\\nQuestion\\nAnswer\\nKnowledge\\nGraph\\n(a) Retrieval-based LLM Reasoning\\nLLM\\nReasoning\\n(b) Agent-based LLM Reasoning\\n(c) Ours: Knowledge Graph-constrained LLM Reasoning\\nQ:\\xa0Who is\\nthe spouse\\nof the ex-\\npresident of\\nUSA?\\nt=2\\nA: Based on the paths,\\nthe answers are: Laura\\nBush, Michelle Obama,\\nMelania Trump.\\nKG-specialized\\nLLM\\nKG-Trie\\nConstraint\\xa0\\n①\\xa0Offline KG-Trie\\nConstruction\\n②\\xa0Graph-constrained\\nDecoding\\nt=1\\nReasoning Paths and\\xa0\\n\\xa0\\xa0Hypothesis\\xa0Answers\\nGeneral\\nLLM\\n③\\xa0Inductive\\nReasoning\\n# Reasoning Path:\\n# Answer:\\nLaura Bush\\n# Reasoning Path:\\n# Answer:\\nMichelle Obama\\nQ\\nKnowledge\\nRetriever\\nA\\nRetrieved\\nFacts\\nt=1\\nLLM\\nEx-president\\nFounded_in\\n1776\\nUSA\\nBarack Obama\\nBorn_in\\nHonolulu\\nMichelle\\nObama\\nSasha Obama\\nMorther_of\\nLLM Agent\\nA\\nSpouse_of\\nt=1\\nt=2\\nt=3\\nT Steps\\nUSA\\nDonald Trump\\nEx-president\\nMichelle\\nObama\\nGeorge W.\\nBush\\xa0\\nEx-president\\nBarack Obama\\nEx-president\\nSpouse_of\\n1776\\nFounded_in\\nWashington\\nD.C.\\nCapital\\nLaura\\nBush\\xa0\\nKnowledge Graph\\nMelania\\nTrump\\nMarry_to\\nIvana\\nTrump\\nEx-wife\\nSpouse_of\\nQ\\nFigure 2: Illustration of existing KG-enhanced LLM reasoning paradigms and proposed graph-\\nconstrained reasoning (GCR). 1) First, given a KG, we convert it into the KG-Trie, serving as a\\nstructured index to facilitate efficient reasoning path searches using LLMs. 2) Then, we design a\\ngraph-constrained decoding process that employs a lightweight KG-specialized LLM to generate\\nmultiple KG-grounded reasoning paths and hypothesis answers. This ensures the faithfulness of the\\nreasoning process while leveraging the strong capabilities of LLMs to efficiently explore reasoning\\npaths within KGs. 3) Finally, we input the generated reasoning paths and hypothesis answers into a\\npowerful general LLM to utilize its inductive reasoning ability to produce final answers.\\net al., 2023) retrieve facts from an external knowledge graph to guide the CoT performed by LLMs.\\nRoG (Luo et al., 2024) proposes a planning-retrieval-reasoning framework that retrieves reasoning\\npaths from KGs to guide LLMs conducting faithful reasoning. To capture graph structure, GNN-\\nRAG (Mavromatis & Karypis, 2024) adopts a lightweight graph neural network to effectively re-\\ntrieve from KGs. Instead of retrieving, StructGPT (Jiang et al., 2023) and ToG (Sun et al., 2024)\\ntreat LLMs as agents to interact with KGs to find reasoning paths leading to the correct answers.\\n3\\nPRELIMINARY\\nKnowledge Graphs (KGs) represent a wealth of factual knowledge as a collection of triples: G =\\n{(e, r, e′) ∈E × R × E}, where E and R denote the set of entities and relations, respectively.\\nReasoning Paths are sequences of consecutive triples in KGs: wz = e0\\nr1\\n−→e1\\nr2\\n−→. . .\\nrl\\n−→el,\\nwhere ∀(ei−1, ri, ei) ∈G. The paths reveal the connections between knowledge that potentially\\nfacilitate reasoning. For example, the reasoning path: wz = Alice\\nmarry to\\n−−−−−−→Bob\\nfather of\\n−−−−−−→\\nCharlie indicates that “Alice” is married to “Bob” and “Bob” is the father of “Charlie”. Therefore,\\n“Alice” could be reasoned to be the mother of “Charlie”.\\nKnowledge Graph Question Answering (KGQA) is a representative reasoning task with the as-\\nsistance of KGs. Given a natural language question q and a KG G, the task aims to design a function\\nf to reason answers a ∈A based on knowledge from G, i.e., a = f(q, G).\\n3\\n4\\nAPPROACH\\n4.1\\nFROM CHAIN-OF-THOUGHT REASONING TO GRAPH-CONSTRAINED REASONING\\nChain-of-Thought Reasoning (CoT) (Wei et al., 2022) has been widely adopted to enhance the\\nreasoning ability of LLMs by autoregressively generating a series of reasoning steps leading to the\\nanswer. Specifically, given a question q, CoT models the joint probability of the answer a and\\nreasoning steps z as\\nP(a|q) =\\nX\\nz\\nPθ(a|z, q)Pθ(z|q) =\\nX\\nz\\nPθ(a|q, z)\\n|z|\\nY\\ni=1\\nPθ(zi|q, z1:i−1),\\n(1)\\nwhere q denotes the input question, a denotes the final answer, θ denotes the parameters of LLMs,\\nand zi denotes the i-th step of the reasoning process z. To further enhance the reasoning ability,\\nmany previous works focus on improving the reasoning process Pθ(z|q) by exploring and aggregat-\\ning multiple reasoning processes (Wang et al., 2024; Yao et al., 2024).\\nDespite the effectiveness, a major issue remains the faithfulness of the reasoning process generated\\nby LLMs (Huang et al., 2024). The reasoning is represented as a sequence of tokens decoded\\nstep-by-step, which can accumulate errors and result in hallucinated reasoning paths and answers\\n(Nguyen et al., 2024). To address these issues, we utilize knowledge graphs (KGs) to guide LLMs\\ntoward faithful reasoning.\\nKG-enhanced Reasoning utilizes the structured knowledge in KGs to improve the reasoning of\\nLLMs (Luo et al., 2024; Sun et al., 2024), which can generally be expressed as finding a reasoning\\npath wz on KGs that connects the entities mentioned in the question and the answer. This can be\\nformulated as\\nP(a|q, G) =\\nX\\nwz\\nPϕ(a|q, wz)Pϕ(wz|q, G),\\n(2)\\nwhere Pϕ(wz|q, G) denotes the probability of discovering a reasoning path wz on KGs G given the\\nquestion q by a function parameterized by ϕ. To acquire reasoning paths for reasoning, most prior\\nstudies follow the retrieval-based (Li et al., 2023) or agent-based paradigm (Sun et al., 2024), as\\nshown in Figure 2 (a) and (b), respectively. Nevertheless, retrieval-based methods rely on precise\\nadditional retrievers, while agent-based methods are computationally intensive and lead to high\\nlatency. To address these issues, we propose a novel graph-constrained reasoning paradigm (GCR).\\nGraph-constrained Reasoning (GCR) directly incorporates KGs into the decoding process of\\nLLMs to achieve faithful reasoning. The overall framework of GCR is illustrated in Figure 2 (c),\\nwhich consists of three main components: 1) Knowledge Graph Trie Construction: building a\\nstructural index of KG to guide LLM reasoning, 2) Graph-constrained Decoding: generating KG-\\ngrounded paths and hypothesis answers using LLMs, and 3) Graph Inductive Reasoning: reasoning\\nover multiple paths and hypotheses to derive final answers.\\n4.2\\nKNOWLEDGE GRAPH TRIE CONSTRUCTION\\nKnowledge graphs (KGs) store abundant knowledge in a structured format. However, large language\\nmodels (LLMs) struggle to efficiently access and reason on KGs due to their unstructured nature. To\\naddress this issue, we propose to convert KGs into knowledge graph Tries (KG-Tries), which serve\\nas a structured index of KGs to facilitate efficient reasoning on graphs using LLMs.\\nA Trie (a.k.a. prefix tree) (Wikipedia contributors, 2024; Fredkin, 1960) is a tree-like data structure\\nthat stores a dynamic set of strings, where each node represents a common prefix of its children.\\nTries can be used to restrict LLM output tokens to those starting with valid prefixes (De Cao et al.,\\n2022; Xie et al., 2022; Chen et al., 2022). The tree structure of Trie is an ideal choice for encoding\\nthe reasoning paths in KGs for LLMs to efficiently traverse.\\nWe first adopt the breadth-first search (BFS) algorithm to retrieve reasoning paths Wz within L hops\\nstarting from entities mentioned in the questions. The retrieved paths are formatted as sentences\\nusing the template shown in Figure 7. The formatted sentences are then split into tokens by the\\n4\\ntokenizer of LLM and stored as a KG-Trie CG. The overall process can be formulated as:\\nWz = BFS(G, {eq}, L),\\n(3)\\nTz = Tokenizer(Wz),\\n(4)\\nCG = Trie(Tz),\\n(5)\\nwhere eq denotes the entities mentioned in the question, L denotes the maximum hops of paths, and\\nTz denotes the tokens of reasoning paths. The KG-Trie CG is used as a constraint to guide the LLM\\ndecoding process.\\nBy constructing KG-Trie for each question entity, we can enable efficient traversal of reasoning paths\\nin constant time (O(|Wz|)) without costly graph traversal (Sun et al., 2024). Moreover, KG-Trie can\\nbe pre-constructed offline and loaded during reasoning. This significantly reduces the computational\\ncost and latency of reasoning on KGs, making it feasible for real-time applications.\\n============================= Prompt Input ================================\\nPlease generate some reasoning paths in the KG starting from the topic entities to answer the question.\\n# Question: what is the name of justin bieber brother?\\n============================= LLM Output ================================\\n# Reasoning Path: <PATH> Justin Bieber →people.person.parents →Jeremy Bieber →peo-\\nple.person.children →Jaxon Bieber </PATH>\\n# Answer: Jaxon Bieber\\nFigure 3: An example of the graph-constrained decoding. Detailed prompts can be found in Figure 8.\\n4.3\\nGRAPH-CONSTRAINED DECODING\\nLarge language models (LLMs) have strong reasoning capabilities but still suffer from severe hal-\\nlucination issues, which undermines the trustworthiness of the reasoning process. To tackle this\\nissue, we propose graph-constrained decoding, which unifies the reasoning ability of LLMs with the\\nstructured knowledge in KGs to generate faithful KG-grounded reasoning paths leading to answers.\\nGiven a question q, we design an instruction prompt to harness the reasoning ability of LLMs to\\ngenerate reasoning paths wz and hypothesis answers a. To eliminate the hallucination during rea-\\nsoning on KGs, we adopt the KG-Trie CG as constraints to guide the decoding process of LLMs and\\nonly generate reasoning paths that are valid in KGs, formulated as:\\nPϕ(a, wz|q) = Pϕ(a|q, wz)\\n|\\n{z\\n}\\nRegular decoding\\nGraph-constrained decoding\\nz\\n}|\\n{\\n|wz|\\nY\\ni=1\\nPϕ(wzi|q, wz1:i−1)CG(wzi|wz1:i−1),\\n(6)\\nCG(wzi|wz1:i−1) =\\n\\x1a1, ∃prefix(wz1:i, wz), ∃wz ∈Wz,\\n0, else,\\n(7)\\nwhere wzi denotes the i-th token of the reasoning path wz, Pϕ denotes the token probabilities\\npredicted by the LLM with parameters ϕ, and CG(wzi|wz1:i−1) denotes the constraint function that\\nchecks whether the generated tokens wz1:i is a valid prefix of the reasoning path using KG-Trie.\\nAfter a valid reasoning path is generated, we switch back to the regular decoding process to generate\\na hypothesis answer conditioned on the path.\\nTo further enhance KG reasoning ability, we fine-tune a lightweight KG-specialized LLM with\\nparameters ϕ on the graph-constrained decoding task. Specifically, given a question q, the LLM is\\noptimized to generate relevant reasoning paths wz that are helpful for answering the question, then\\nprovide a hypothesis answer a based on it, which can be formulated as:\\nL = E(q,wz,a)∼DG log Pϕ(a, wz|q) = E\\n\\uf8ee\\n\\uf8f0log\\n|a|\\nY\\ni=1\\nPϕ(ai|q, wz, a1:i−1)\\n|wz|\\nY\\nj=1\\nPϕ(wzj|q, wz1:j−1)\\n\\uf8f9\\n\\uf8fb,\\n(8)\\nwhere ai and wzj denote the i-th token of the answer a and the j-th token of the reasoning path wz,\\nrespectively.\\n5\\nThe training data (q, wz, a) ∈DG consists of question-answer pairs and reasoning paths generated\\nfrom KGs. We use the shortest paths connecting the entities in the question and answer as the\\nreasoning path wz for training, where details can be found in Section 7. An example of graph-\\nconstrained decoding is illustrated in Figure 3, where <PATH> and </PATH> are special tokens\\nto control the start and end of graph-constrained decoding. Experiment results in Section 5.2 show\\nthat even a lightweight KG-specialized LLM (0.5B) can achieve satisfactory performance in KG\\nreasoning.\\nThe graph-constrained decoding method differs from retrieval-based methods by integrating a pre-\\nconstructed KG-Trie into the decoding process of LLMs. This not only reduces input tokens, but\\nalso bridges the gap between unstructured reasoning in LLMs and structured knowledge in KGs,\\nallowing for efficient reasoning on KGs regardless of its scale, which results in faithful reasoning\\nleading to answers. Additionally, experimental results in Section 5.4 demonstrate that KG-Trie can\\nintegrate with new KGs on the fly, showcasing its zero-shot generalizability for reasoning on unseen\\nKGs without further training.\\n4.4\\nGRAPH INDUCTIVE REASONING\\nGraph-constrained decoding harnesses the reasoning ability of a KG-specialized LLM to generate a\\nfaithful reasoning path and a hypothesis answer. However, complex reasoning tasks typically admit\\nmultiple reasoning paths that lead to correct answers (Stanovich et al., 2000). Incorporating diverse\\nreasoning paths would be beneficial for deliberate thinking and reasoning (Evans, 2010; Wang et al.,\\n2024). To this end, we propose to input multiple reasoning paths and hypothesis answers generated\\nby the KG-specialized LLM into a powerful general LLM to leverage its inductive reasoning ability\\nto produce final answers.\\nThe graph-constrained decoding seamlessly integrates into the decoding process of LLMs, allowing\\nit to be paired with various LLM generation strategies like beam-search (Federico et al., 1995) to\\ntake advantage of the GPU parallel computation. Thus, given a question, we adopt graph-constrained\\ndecoding to simultaneously generate K reasoning paths and hypothesis answers with beam search in\\na single LLM call, which are then inputted into a general LLM to derive final answers. The overall\\nprocess can be formulated as:\\nZK = {ak, wk\\nz}K\\nk=1 = arg top-K Pϕ(a, wz|q),\\n(9)\\nPθ(A|q, ZK) ≃\\nK\\nY\\nk=1\\nPθ(A|q, ak, wk\\nz),\\n(10)\\nwhere θ denotes the parameters of the general LLM, ZK denotes the set of top-K reasoning paths\\nand hypothesis answers, and A denotes the final answers.\\nWe follow the FiD framework (Izacard & Grave, 2021; Singh et al., 2021) to incorporate multiple\\nreasoning paths and hypothesis answers to conduct inductive reasoning within one LLM call, i.e.,\\nPθ(A|q, ZK), where detailed prompts can be found in Figure 9. The general LLM can be any\\npowerful LLM, such as ChatGPT (OpenAI, 2022), or Llama-3 (Meta, 2024), which can effectively\\nleverage their internal reasoning ability to reason over multiple reasoning paths to produce final\\nanswers without additional fine-tuning.\\n5\\nEXPERIMENT\\nIn our experiments, we aim to answer the following research questions: RQ1: Can GCR achieve\\nstate-of-the-art reasoning performance with balances between efficiency and effectiveness? RQ2:\\nCan GCR eliminate hallucinations and conduct faithful reasoning? RQ3: Can GCR generalize to\\nunseen KGs on the fly?\\n5.1\\nEXPERIMENT SETUPS\\nDatasets. Following previous research (Luo et al., 2024; Sun et al., 2024), we first evaluate the\\nreasoning ability of GCR on two benchmark KGQA datasets: WebQuestionSP (WebQSP) (Yih et al.,\\n2016) and Complex WebQuestions (CWQ) (Talmor & Berant, 2018). Freebase (Bollacker et al.,\\n6\\nTable 1: Performance comparison with different baselines on the two KGQA datasets.\\nTypes\\nMethods\\nWebQSP\\nCWQ\\nHit\\nF1\\nHit\\nF1\\nLLM Reasoning\\nQwen2-0.5B (Yang et al., 2024a)\\n26.2\\n17.2\\n12.5\\n11.0\\nQwen2-1.5B (Yang et al., 2024a)\\n41.3\\n28.0\\n18.5\\n15.7\\nQwen2-7B (Yang et al., 2024a)\\n50.8\\n35.5\\n25.3\\n21.6\\nLlama-2-7B (Touvron et al., 2023)\\n56.4\\n36.5\\n28.4\\n21.4\\nLlama-3.1-8B (Meta, 2024)\\n55.5\\n34.8\\n28.1\\n22.4\\nGPT-4o-mini (OpenAI, 2024a)\\n63.8\\n40.5\\n63.8\\n40.5\\nChatGPT (OpenAI, 2022)\\n59.3\\n43.5\\n34.7\\n30.2\\nChatGPT+Few-shot (Brown et al., 2020)\\n68.5\\n38.1\\n38.5\\n28.0\\nChatGPT+CoT (Wei et al., 2022)\\n73.5\\n38.5\\n47.5\\n31.0\\nChatGPT+Self-Consistency (Wang et al., 2024)\\n83.5\\n63.4\\n56.0\\n48.1\\nGraph Reasoning\\nGraftNet (Sun et al., 2018)\\n66.7\\n62.4\\n36.8\\n32.7\\nNSM (He et al., 2021)\\n68.7\\n62.8\\n47.6\\n42.4\\nSR+NSM (Zhang et al., 2022)\\n68.9\\n64.1\\n50.2\\n47.1\\nReaRev (Mavromatis & Karypis, 2022)\\n76.4\\n70.9\\n52.9\\n47.8\\nKG+LLM\\nKD-CoT (Wang et al., 2023)\\n68.6\\n52.5\\n55.7\\n-\\nEWEK-QA (Dehghan et al., 2024)\\n71.3\\n-\\n52.5\\n-\\nToG (ChatGPT) (Sun et al., 2024)\\n76.2\\n-\\n57.6\\n-\\nToG (GPT-4) (Sun et al., 2024)\\n82.6\\n-\\n68.5\\n-\\nEffiQA (Dong et al., 2024)\\n82.9\\n-\\n69.5\\nRoG (Llama-2-7B) (Luo et al., 2024)\\n85.7\\n70.8\\n62.6\\n56.2\\nGNN-RAG (Mavromatis & Karypis, 2024)\\n85.7\\n71.3\\n66.8\\n59.4\\nGNN-RAG+RA (Mavromatis & Karypis, 2024)\\n90.7\\n73.5\\n68.7\\n60.4\\nGCR (Llama-3.1-8B + ChatGPT)\\n92.6\\n73.2\\n72.7\\n60.9\\nGCR (Llama-3.1-8B + GPT-4o-mini)\\n92.2\\n74.1\\n75.8\\n61.7\\n2008) is adopted as the knowledge graph for both datasets. To further evaluate the generalizability\\nof GCR, we conduct zero-shot transfer experiments on two new KGQA datasets: CommonsenseQA\\n(CSQA) (Talmor et al., 2019) and MedQA-USMLE (MedQA) (Jin et al., 2021). For CSQA, we use\\nConceptNet (Speer et al., 2017) as the KG, while for MedQA, we use a medical KG constructed\\nfrom the Unified Medical Language System (Yasunaga et al., 2021). The details of the datasets are\\ndescribed in Section 7.\\nBaselines. We compare GCR with the 22 baselines grouped into three categories: 1) LLM reasoning\\nmethods, 2) graph reasoning methods, and 3) KG-enhanced LLM reasoning methods. The detailed\\nbaselines are listed in Section 8.\\nEvaluation Metrics. We adopt Hit and F1 as the evaluation metrics following previous works (Luo\\net al., 2024; Sun et al., 2024) on WebQSP and CWQ. Hit checks whether any correct answer exists in\\nthe generated predictions, while F1 considers the coverage of all answers by balancing the precision\\nand recall of predictions. Because CSQA and MedQA are multiple-choice QA datasets, we adopt\\naccuracy as the evaluation metric.\\nImplementations. For GCR, we use the KG-Trie to index all the reasoning paths within 2 hops\\nstarting from question entities. For the LLMs, we use a fine-tuned Llama-3-8B (Meta, 2024) as\\nthe KG-specialized LLM. We generate top-10 reasoning paths and hypothesis answers from graph-\\nconstrained decoding. We adopt the advanced ChatGPT (OpenAI, 2022) and GPT-4o-mini (OpenAI,\\n2024a) as the general LLMs for inductive reasoning. The detailed hyperparameters and experiment\\nsettings are described in Section 9.\\n5.2\\nRQ1: REASONING PERFORMANCE AND EFFICIENCY\\nMain Results. In this section, we compare GCR with other baselines on KGQA benchmarks to\\nevaluate the reasoning performance. From the results shown in Table 1, GCR achieves the best\\nperformance on both datasets, outperforming the second-best by 2.1% and 9.1% in terms of Hit on\\nWebQSP and CWQ, respectively. The results demonstrate that GCR can effectively leverage KGs to\\nenhance LLMs and achieve state-of-the-art reasoning performance.\\nAmong the LLM reasoning methods, ChatGPT with self-consistency prompts demonstrates the best\\nperformance, which indicates the powerful reasoning ability inherent in LLMs. However, their per-\\nformances are still limited by the model size and complex reasoning required over structured data.\\nGraph reasoning methods, such as ReaRev, achieve competitive performance on WebQSP by ex-\\n7\\nTable 2: Efficiency and performance comparison of different methods on WebQSP.\\nTypes\\nMethods\\nHit\\nAvg. Runtime (s)\\nAvg. # LLM Calls\\nAvg. # LLM Tokens\\nRetrieval-based\\nS-Bert\\n66.9\\n0.87\\n1\\n293\\nBGE\\n72.7\\n1.05\\n1\\n357\\nOpenAI-Emb.\\n79.0\\n1.77\\n1\\n330\\nGNN-RAG\\n85.7\\n1.52\\n1\\n414\\nRoG\\n85.7\\n2.60\\n2\\n521\\nAgent-based\\nToG\\n75.1\\n16.14\\n11.6\\n7,069\\nEffiQA\\n82.9\\n-\\n7.3\\n-\\nOurs\\nGCR\\n92.6\\n3.60\\n2\\n231\\nplicitly modeling the graph structure. But they struggle to generalize across different datasets and\\nunderperform on CWQ. In KG+LLM methods, both agent-based methods (e.g., ToG, EffiQA) and\\nretrieval-based methods (e.g., RoG, GNN-RAG) achieve the second-best performance. Neverthe-\\nless, they still suffer from inefficiency and reasoning hallucinations which limit their performance.\\nIn contrast, GCR effectively eliminates hallucinations and conducts faithful reasoning by leveraging\\nthe structured KG index and graph-constrained decoding.\\nEfficiency Analysis.\\nTo show the efficiency of GCR, we compare the average runtime, number of LLM calls, and num-\\nber of input tokens with retrieval-based and agent-based methods in Table 2. For retrieval-based\\nmethods, we compare with dense retrievers (e.g., S-Bert (Reimers & Gurevych, 2019), BGE (Zhang\\net al., 2023), OpenAI-Emb. (OpenAI, 2024b)) and graph-based retrievers (e.g., GNN-RAG (Mavro-\\nmatis & Karypis, 2024), RoG (Luo et al., 2024)), which retrieve reasoning paths from KGs and feed\\nthem into LLMs for reasoning answers. For agent-based methods, we compare with ToG (Sun et al.,\\n2024) and EffiQA1 (Dong et al., 2024), which heuristically search on KGs for answers. The detailed\\nsettings are described in Section 9.\\nDense retrievers are most efficient in terms of runtime and LLM calls as they convert all paths into\\nsentences and encode them as embeddings in advance. However, they sacrifice their accuracy in\\nretrieving as they are not designed to encode graph structure. Graph-based retrievers and agent-\\nbased methods achieve better performance by considering graph structure; however, they require\\nmore time and LLM calls. Specifically, the retrieved graph is fed as inputs to LLMs, which leads to\\na large number of input tokens. Agent-based methods, like ToG, require more LLM calls and input\\ntokens as the question difficulty increases due to their iterative reasoning process. In contrast, GCR\\nachieves the best performance with a reasonable runtime and number of LLM calls. With the help\\nof KG-Trie, GCR explores multiple reasoning paths at the same time during the graph-constrained\\ndecoding, which does not involve additional LLM calls or input tokens and benefits from the parallel\\nGPU computation with low latency. More efficiency analysis under different beam sizes used for\\ngraph-constrained decoding can be found in parameter analysis.\\nTable 3: Ablation studies of GCR on two KGQA datasets.\\nVariants\\nWebQSP\\nCWQ\\nF1\\nPrecision\\nRecall\\nF1\\nPrecision\\nRecall\\nGCR (Llama-3.1-8B + ChatGPT)\\n73.2\\n80.0\\n76.9\\n60.9\\n61.1\\n66.6\\nGCR w/o KG-specialized LLM\\n52.9\\n66.3\\n50.2\\n37.5\\n40.8\\n37.9\\nGCR w/o General LLM\\n57.0\\n58.0\\n70.1\\n39.4\\n32.8\\n64.3\\nAblation Study. We first conduct an\\nablation study to analyze the effec-\\ntiveness of the KG-specialized LLM\\nand general LLM in GCR. As shown\\nin Table 3, the full GCR achieves the\\nbest performance on both datasets.\\nBy removing the KG-specialized LLM, we feed all 2-hop reasoning paths into the general LLM.\\nThis results in a significant performance drop, indicating its importance in utilizing reasoning abil-\\nity to find relevant paths on KGs for reasoning. On the other hand, removing the general LLM\\nand relying solely on answers predicted by KG-specialized LLM leads to a noticeable decrease in\\nprecision, due to noises in its predictions. This highlighting the necessity of the general LLM for\\nconducting inductive reasoning over multiple paths to derive final answers.\\nDifferent LLMs. We further analyze LLMs used for KG-specialized and general LLMs in Table 4.\\nFor KG-specialized LLMs, we directly plug the KG-Trie into different LLMs to conduct graph-\\nconstrained decoding and use the same general LLM for final reasoning. For general LLMs, we\\nadopt the same reasoning paths generated by KG-specialized LLMs to different LLMs to produce\\nfinal answers. For zero-shot and few-shot learning, we adopt the original LLMs without fine-tuning,\\nwhose prompt templates can be found in Figures 8 and 10.\\n1Since there is no available code for EffiQA, we directly copy the results from the original paper.\\n8\\nTable 4: Comparison of different LLMs used in\\nGCR on WebQSP.\\nComponents\\nLearning Types\\nVariants\\nHit\\nF1\\nKG-specialized\\nLLM\\nZero-shot\\nLlama-3.1-8B\\n28.25\\n10.32\\nLlama-3.1-70B\\n38.53\\n12.53\\nFew-shot\\nLlama-3.1-8B\\n33.24\\n11.19\\nLlama-3.1-70B\\n41.13\\n13.14\\nFine-tuned\\nQwen2-0.5B\\n87.48\\n60.03\\nQwen2-1.5B\\n89.21\\n62.97\\nQwen2-7B\\n92.31\\n72.74\\nLlama-2-7B\\n92.55\\n73.23\\nLlama-3.1-8B\\n92.74\\n73.14\\nGeneral LLM\\nZero-shot\\nQwen-2-7B\\n86.32\\n67.59\\nLlama-3.1-8B\\n90.24\\n71.19\\nLlama-3.1-70B\\n90.24\\n71.19\\nChatGPT\\n92.55\\n73.23\\nGPT-4o-mini\\n92.23\\n74.05\\nResults in Table 4 show that a lightweight LLM\\n(0.5B) can outperform a large one (70B) af-\\nter fine-tuning, indicating the effectiveness of\\nfine-tuning in enhancing the ability of LLMs\\nand make them specialized for KG reason-\\ning.\\nHowever, the larger LLMs (e.g., 7B\\nand 8B) still perform better than smaller ones,\\nhighlighting the importance of model capac-\\nity in searching relevant reasoning paths on\\nKGs.\\nSimilar trends are observed in gen-\\neral LLMs where larger models (e.g., GPT-4o-\\nmini and ChatGPT) outperform smaller ones\\n(e.g., Qwen-2-7B and Llama-3.1-8B), show-\\ncasing their stronger inductive reasoning abili-\\nties. This further emphasizes the need of paring\\npowerful general LLMs with lightweight KG-specialized LLMs to achieve better reasoning driven\\nby both of them.\\n1\\n3\\n5\\n10\\n20\\nGraph-constrained decoding beam size K\\n0\\n2\\n4\\n6\\n8\\nGeneration Time (s)\\n40\\n50\\n60\\n70\\n80\\n90\\nAnswer Coverage (%)\\nGeneration Time (s)\\nHit\\nF1\\nPrecision\\nRecall\\nFigure 4: Parameter analysis of beam\\nsize K.\\nParameter Analysis. We first analyze the impact of dif-\\nferent beam sizes K for graph-constrained decoding on\\nthe performance of GCR. We conduct the experiments on\\nWebQSP with different beam sizes of 1, 3, 5, 10, and 20.\\nThe results are shown in Figure 4. We observe that the hit\\nand recall of GCR increase with the beam size. Because,\\nwith a larger beam size, the LLMs can explore more rea-\\nsoning paths and find the correct answers. However, the\\nF1 score, peaks when the beam size is set to 10. This is\\nbecause the beam size of 10 can provide a balance be-\\ntween the exploration and exploitation of the reasoning\\npaths. When the beam size is set to 20, the performance\\ndrops due to the increased complexity of the search space,\\nwhich may introduce noise and make the reasoning less\\nreliable. This also highlights the importance of using general LLMs to conduct inductive reason-\\ning over multiple paths to disregard the noise and find the correct answers. Although the graph-\\nconstrained decoding benefits from the parallel GPU computation to explore multiple reasoning\\npaths at the same time, the time cost still slightly increases from 1.4s to 7.8s with the increase of\\nthe beam size. Thus, we set the beam size to 10 in the experiments to balance the performance and\\nefficiency. We also investigate the impact of L hops paths used for KG-Trie construction in Sec-\\ntion 10.1. The results show that GCR can achieve a good balance between reasoning performance\\nand efficiency by setting L = 2 and K = 10.\\n5.3\\nRQ2: HALLUCINATION ELIMINATION AND FAITHFUL REASONING\\nIn this section, we investigate the effectiveness of KG constraints in eliminating hallucinations and\\nensuring faithful reasoning. We first compare the difference of answer accuracy (Hit) and faithful\\nreasoning ratio by removing KG constraints in graph-constrained decoding. The faithful reasoning\\nratio is calculated as the percentage of faithful reasoning in correctly predicted answers. We define\\na reasoning as faithful where the generated reasoning path can be found in KGs, and vice versa.\\nGCR GCR w/o constraint\\n0\\n20\\n40\\n60\\nAnswer Hit\\n100.0%\\n62.4%\\nWebQSP\\nFaithful Reasoning\\nError Reasoning\\nGCR GCR w/o constraint\\n0\\n20\\n40\\n60\\nAnswer Hit\\n100.0%\\n48.1%\\nCWQ\\nFigure 5: Analysis of performance and reasoning\\nerrors in GCR.\\nFrom the Figure 5, we can observe that GCR\\nachieves the 100% faithful reasoning ratio on\\nboth datasets, which indicates that GCR can\\neliminate hallucinations and ensure faithful rea-\\nsoning during reasoning on KGs. In contrast,\\nwhen removing KG constraints, both the an-\\nswer accuracy and faithful reasoning decrease\\nsignificantly on WebQSP. This shows that KG\\nconstraints not only improve reasoning by re-\\nducing the searching space, but also play a cru-\\ncial role in preventing hallucinations for accu-\\n9\\nTable 5: Examples of the faithful reasoning conducted by GCR. Red denotes the incorrect reasoning\\npaths and answers, while bold denotes the correct paths and answers.\\nCase 1: Incorrect answers and hallucinated reasoning paths without constraints.\\nQuestion\\nWho is niall ferguson ’s wife?\\nAnswer\\nAyaan Hirsi Ali\\nGCR w/o constraint\\n# Reasoning Path: Niall Ferguson →people.person.children →Mabel Rose Ferguson →\\npeople.person.parents →Alyssa Mastromonaco\\n#Answer: Alyssa Mastromonaco\\nGCR\\n# Reasoning Path: Niall Ferguson →people.person.children →Thomas Ferguson →peo-\\nple.person.parents →Ayaan Hirsi Ali\\n#Answer: Ayaan Hirsi Ali\\nCase 2: Correct answers but hallucinated reasoning paths without constraints.\\nQuestion\\nWhere is jamarcus russell from?\\nAnswer\\nMobile\\nGCR w/o constraint\\n# Reasoning Path: JaMarcus Russell →people.person.place of birth →Tampa\\n#Answer: Mobile, Alabama\\nGCR\\n# Reasoning Path: JaMarcus Russell →people.person.place of birth →Mobile\\n#Answer: Mobile\\nrate reasoning. While the answer hit rate on CWQ remains almost unchanged, the ratio of faithful\\nreasoning still decreases to 48.1%. This implies that even if LLMs can produce correct answers, the\\nreasoning process is still prone to hallucinations and cannot be trusted, which is aligned with the\\nfindings in previous studies (Nguyen et al., 2024).\\nCase Study. We further provide a case study to illustrate the effectiveness of GCR in eliminating\\nhallucinations and ensuring faithful reasoning. As shown in Table 5, the first case demonstrates that,\\nwithout constraints, the model generates an incorrect reasoning path leading to an incorrect answer\\nby hallucinating facts such as “Mabel Rose Ferguson is the child of Naill Ferguson and her parent\\nis Alyssa Mastromonaco”. In contrast, GCR generates a faithful reasoning path grounded in KGs\\nthat “Naill Ferguson has a child named Thomas Ferguson who has a parent named Ayaan Hirsi Ali”.\\nBased on the paths we can reason the correct answer to the question is “Ayaan Hirsi Ali”. In the\\nsecond case, although the LLM answers the question correctly, the generated reasoning path is still\\nhallucinated with incorrect facts. Conversely, GCR conducts faithful reasoning with both correct\\nanswer and reasoning path. These results demonstrate that GCR can effectively eliminate hallucina-\\ntions and ensure faithful reasoning by leveraging KG constraints in graph-constrained decoding.\\n5.4\\nRQ3: ZERO-SHOT GENERALIZABILITY TO UNSEEN KGS\\nTable 6: Zero-shot transferabil-\\nity to other KGQA datasets.\\nModel\\nCSQA\\nMedQA\\nChatGPT\\n79\\n64\\nGCR (ChatGPT)\\n85\\n66\\nGPT-4o-mini\\n91\\n75\\nGCR (GPT-4o-mini)\\n94\\n79\\nIn GCR, the knowledge graph is converted into a constraint which\\nis plugged into the decoding process of LLMs. This allows GCR\\nto generalize to unseen KGs without further training. To evaluate\\nthe generalizability of GCR, we conduct zero-shot transfer ex-\\nperiments on two unseen KGQA datasets: CSQA (Talmor et al.,\\n2019) and MedQA (Jin et al., 2021). Specifically, we use the\\nsame KG-specialized LLM (Llama-3.1-8B) trained on Freebase\\nas well as two general LLMs (ChatGP, GPT-4o-mini). During\\nreasoning, we directly plug the KG-Trie constructed from ConceptNet and medical KGs into the\\nGCR to conduct graph-constrained decoding without additional fine-tuning. The results are shown\\nin Table 6.\\nFrom the results, it is evident that GCR outperforms ChatGPT and GPT-4o-mini in zero-shot per-\\nformance on both datasets. Specifically, GCR shows a 7.6% increase in accuracy on CSQA and a\\n3.1% improvement on MedQA compared to ChatGPT. This highlights the strong zero-shot general-\\nizability of its graph reasoning capabilities to unseen KGs without additional training. However, the\\nimprovement on MedQA is not as significant as that on CSQA. We hypothesize this difference may\\nbe due to LLMs having more common sense knowledge, which aids in reasoning on common sense\\nknowledge graphs effectively. On the other hand, medical KGs are more specialized and require\\ndomain-specific knowledge for reasoning, potentially limiting the generalizability of our method.\\n10\\n6\\nCONCLUSION\\nIn this paper, we introduce a novel LLM reasoning paradigm called graph-constrained reasoning\\n(GCR) to eliminate hallucination and ensure faithful reasoning by incorporating structured KGs. To\\nbridge the unstructured reasoning in LLMs with the structured knowledge in KGs, we propose a\\nKG-Trie to encode paths in KGs using a trie-based index. KG-Trie constrains the decoding process\\nto guide a KG-specialized LLM to generate faithful reasoning paths grounded in KGs. By impos-\\ning constraints, we can not only eliminate hallucination in reasoning but also reduce the reasoning\\ncomplexity, contributing to more efficient and accurate reasoning. Last, a powerful general LLM is\\nutilized as a complement to inductively reason over multiple reasoning paths to generate the final\\nanswer. Extensive experiments demonstrate that GCR excels in faithful reasoning and generalizes\\nwell to reason on new KGs without additional fine-tuning.\\nACKNOWLEDGMENTS\\nWe would want to express our sincere gratitude to Yuan-Fang Li for his valuable feedback and\\nsuggestions during the preparation of this work.\\nREFERENCES\\nGarima Agrawal, Tharindu Kumarage, Zeyad Alghamdi, and Huan Liu. Mindful-rag: A study of\\npoints of failure in retrieval augmented generation. arXiv preprint arXiv:2407.12216, 2024.\\nKurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. Freebase: a collab-\\noratively created graph database for structuring human knowledge. In Proceedings of the 2008\\nACM SIGMOD international conference on Management of data, pp. 1247–1250, 2008.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\\nfew-shot learners. Advances in Neural Information Processing Systems, 33:1877–1901, 2020.\\nChen Chen, Yufei Wang, Bing Li, and Kwok-Yan Lam. Knowledge is flat: A seq2seq generative\\nframework for various knowledge graph completion. In Proceedings of the 29th International\\nConference on Computational Linguistics, pp. 4005–4017, 2022.\\nNicola De Cao, Gautier Izacard, Sebastian Riedel, and Fabio Petroni. Autoregressive entity retrieval.\\nIn International Conference on Learning Representations, 2022.\\nMohammad Dehghan, Mohammad Alomrani, Sunyam Bagga, David Alfonso-Hermelo, Khalil Bibi,\\nAbbas Ghaddar, Yingxue Zhang, Xiaoguang Li, Jianye Hao, Qun Liu, Jimmy Lin, Boxing Chen,\\nPrasanna Parthasarathi, Mahdi Biparva, and Mehdi Rezagholizadeh. EWEK-QA : Enhanced web\\nand efficient knowledge graph retrieval for citation-based question answering systems. In Lun-\\nWei Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting\\nof the Association for Computational Linguistics (Volume 1: Long Papers), pp. 14169–14187,\\nBangkok, Thailand, August 2024. Association for Computational Linguistics. URL https:\\n//aclanthology.org/2024.acl-long.764.\\nZixuan Dong, Baoyun Peng, Yufei Wang, Jia Fu, Xiaodong Wang, Yongxue Shan, and Xin Zhou. Ef-\\nfiqa: Efficient question-answering with strategic multi-model collaboration on knowledge graphs.\\narXiv preprint arXiv:2406.01238, 2024.\\nJonathan St BT Evans. Intuition and reasoning: A dual-process perspective. Psychological Inquiry,\\n21(4):313–326, 2010.\\nMarcello Federico, Mauro Cettolo, Fabio Brugnara, and Giuliano Antoniol. Language modelling\\nfor efficient beam-search. Computer Speech and Language, 9(4):353–380, 1995.\\nYanlin Feng, Xinyue Chen, Bill Yuchen Lin, Peifeng Wang, Jun Yan, and Xiang Ren. Scalable multi-\\nhop relational reasoning for knowledge-aware question answering. In Proceedings of the 2020\\nConference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1295–1309,\\n2020.\\n11\\nEdward Fredkin. Trie memory. Communications of the ACM, 3(9):490–499, 1960.\\nGaole He, Yunshi Lan, Jing Jiang, Wayne Xin Zhao, and Ji-Rong Wen. Improving multi-hop knowl-\\nedge base question answering by learning intermediate supervision signals. In Proceedings of the\\n14th ACM international conference on web search and data mining, pp. 553–561, 2021.\\nMatthew Douglas Hoffman, Du Phan, David Dohan, Sholto Douglas, Tuan Anh Le, Aaron Parisi,\\nPavel Sountsov, Charles Sutton, Sharad Vikram, and Rif A Saurous. Training chain-of-thought\\nvia latent-variable inference. Advances in Neural Information Processing Systems, 36, 2024.\\nJie Huang and Kevin Chen-Chuan Chang. Towards reasoning in large language models: A survey.\\nIn Findings of the Association for Computational Linguistics: ACL 2023, pp. 1049–1065, 2023.\\nJie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song,\\nand Denny Zhou.\\nLarge language models cannot self-correct reasoning yet.\\nIn The Twelfth\\nInternational Conference on Learning Representations, 2024.\\nGautier Izacard and ´Edouard Grave. Leveraging passage retrieval with generative models for open\\ndomain question answering. In Proceedings of the 16th Conference of the European Chapter of\\nthe Association for Computational Linguistics: Main Volume, pp. 874–880, 2021.\\nJinhao Jiang, Kun Zhou, Xin Zhao, and Ji-Rong Wen. Unikgqa: Unified retrieval and reasoning\\nfor solving multi-hop question answering over knowledge graph. In The Eleventh International\\nConference on Learning Representations, 2022.\\nJinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, and Ji-Rong Wen. Structgpt: A\\ngeneral framework for large language model to reason over structured data. In Proceedings of the\\n2023 Conference on Empirical Methods in Natural Language Processing, pp. 9237–9251, 2023.\\nJinhao Jiang, Kun Zhou, Wayne Xin Zhao, Yang Song, Chen Zhu, Hengshu Zhu, and Ji-Rong\\nWen. Kg-agent: An efficient autonomous agent framework for complex reasoning over knowl-\\nedge graph. arXiv preprint arXiv:2402.11163, 2024.\\nDi Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits. What dis-\\nease does this patient have? a large-scale open domain question answering dataset from medical\\nexams. Applied Sciences, 11(14):6421, 2021.\\nShiyang Li, Yifan Gao, Haoming Jiang, Qingyu Yin, Zheng Li, Xifeng Yan, Chao Zhang, and Bing\\nYin. Graph reasoning for question answering with triplet retrieval. In Findings of the Association\\nfor Computational Linguistics: ACL 2023, pp. 3366–3375, 2023.\\nLinhao Luo, Yuan-Fang Li, Gholamreza Haffari, and Shirui Pan. Reasoning on graphs: Faithful and\\ninterpretable large language model reasoning. In International Conference on Learning Repre-\\nsentations, 2024.\\nCostas Mavromatis and George Karypis. Rearev: Adaptive reasoning for question answering over\\nknowledge graphs. In Findings of the Association for Computational Linguistics: EMNLP 2022,\\npp. 2447–2458, 2022.\\nCostas Mavromatis and George Karypis. Gnn-rag: Graph neural retrieval for large language model\\nreasoning. arXiv preprint arXiv:2405.20139, 2024.\\nMeta. Build the future of ai with meta llama 3, 2024. URL https://llama.meta.com/\\nllama3/.\\nThi Nguyen, Linhao Luo, Fatemeh Shiri, Dinh Phung, Yuan-Fang Li, Thuy-Trang Vu, and Gho-\\nlamreza Haffari. Direct evaluation of chain-of-thought in multi-hop reasoning with knowledge\\ngraphs. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Findings of the Association\\nfor Computational Linguistics ACL 2024, pp. 2862–2883, Bangkok, Thailand and virtual meeting,\\nAugust 2024. Association for Computational Linguistics. URL https://aclanthology.\\norg/2024.findings-acl.168.\\nOpenAI. Introducing chatgpt, 2022. URL https://openai.com/index/chatgpt/.\\n12\\nOpenAI. Hello gpt-4o, 2024a. URL https://openai.com/index/hello-gpt-4o/.\\nOpenAI.\\nNew embedding models and api updates, 2024b.\\nURL https://openai.com/\\nindex/new-embedding-models-and-api-updates/.\\nOpenAI.\\nLearning to reason with llms, 2024c.\\nURL https://openai.com/index/\\nlearning-to-reason-with-llms/.\\nShirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. Unifying large\\nlanguage models and knowledge graphs: A roadmap. IEEE Transactions on Knowledge and Data\\nEngineering (TKDE), 2024.\\nShuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei\\nHuang, and Huajun Chen. Reasoning with language model prompting: A survey. In Proceedings\\nof the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long\\nPapers), pp. 5368–5393, 2023.\\nNils Reimers and Iryna Gurevych.\\nSentence-bert: Sentence embeddings using siamese bert-\\nnetworks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language\\nProcessing. Association for Computational Linguistics, 11 2019.\\nURL https://arxiv.\\norg/abs/1908.10084.\\nDevendra Singh, Siva Reddy, Will Hamilton, Chris Dyer, and Dani Yogatama. End-to-end training\\nof multi-document reader and retriever for open-domain question answering. Advances in Neural\\nInformation Processing Systems, 34:25968–25981, 2021.\\nRobyn Speer, Joshua Chin, and Catherine Havasi. Conceptnet 5.5: An open multilingual graph of\\ngeneral knowledge. In Proceedings of the AAAI conference on artificial intelligence, volume 31,\\n2017.\\nKE Stanovich, RF West, and R Hertwig. Individual differences in reasoning: Implications for the ra-\\ntionality debate?-open peer commentary-the questionable utility of cognitive ability in explaining\\ncognitive illusions. 2000.\\nYuan Sui, Yufei He, Nian Liu, Xiaoxin He, Kun Wang, and Bryan Hooi.\\nFidelis: Faithful\\nreasoning in large language model for knowledge graph question answering.\\narXiv preprint\\narXiv:2405.13873, 2024.\\nHaitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan Salakhutdinov, and\\nWilliam Cohen. Open domain question answering using early fusion of knowledge bases and\\ntext. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Pro-\\ncessing, pp. 4231–4242, 2018.\\nJiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong, Lionel Ni,\\nHeung-Yeung Shum, and Jian Guo. Think-on-graph: Deep and responsible reasoning of large\\nlanguage model on knowledge graph. In The Twelfth International Conference on Learning Rep-\\nresentations, 2024.\\nAlon Talmor and Jonathan Berant. The web as a knowledge-base for answering complex questions.\\nIn Proceedings of the 2018 Conference of the North American Chapter of the Association for\\nComputational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pp. 641–\\n651, 2018.\\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. Commonsenseqa: A question\\nanswering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference\\nof the North American Chapter of the Association for Computational Linguistics: Human Lan-\\nguage Technologies, Volume 1 (Long and Short Papers), pp. 4149–4158, 2019.\\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-\\nlay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open founda-\\ntion and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.\\n13\\nKeheng Wang, Feiyu Duan, Sirui Wang, Peiguang Li, Yunsen Xian, Chuantao Yin, Wenge Rong,\\nand Zhang Xiong. Knowledge-driven cot: Exploring faithful reasoning in llms for knowledge-\\nintensive question answering. arXiv preprint arXiv:2308.13259, 2023.\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang, Aakanksha\\nChowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language\\nmodels. In The Eleventh International Conference on Learning Representations, 2024.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\\nZhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in\\nNeural Information Processing Systems, 35:24824–24837, 2022.\\nWikipedia contributors. Trie. https://en.wikipedia.org/wiki/Trie, 2024. Accessed:\\n2024-09-11.\\nZonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A\\ncomprehensive survey on graph neural networks. IEEE transactions on neural networks and\\nlearning systems, 32(1):4–24, 2020.\\nXin Xie, Ningyu Zhang, Zhoubo Li, Shumin Deng, Hui Chen, Feiyu Xiong, Mosha Chen, and\\nHuajun Chen. From discrimination to generation: Knowledge graph completion with generative\\ntransformer. In Companion Proceedings of the Web Conference 2022, pp. 162–165, 2022.\\nAn Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,\\nChengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang,\\nJialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai,\\nJinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng\\nXue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai\\nBai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan\\nZhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Yang Fan, Yang Yao, Yichang\\nZhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zhihao Fan. Qwen2\\ntechnical report. arXiv preprint arXiv:2407.10671, 2024a.\\nRui Yang, Haoran Liu, Qingcheng Zeng, Yu He Ke, Wanxin Li, Lechao Cheng, Qingyu Chen, James\\nCaverlee, Yutaka Matsuo, and Irene Li. Kg-rank: Enhancing large language models for medical\\nqa with knowledge graphs and ranking techniques. arXiv preprint arXiv:2403.05881, 2024b.\\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik\\nNarasimhan. Tree of thoughts: Deliberate problem solving with large language models. Ad-\\nvances in Neural Information Processing Systems, 36, 2024.\\nMichihiro Yasunaga, Hongyu Ren, Antoine Bosselut, Percy Liang, and Jure Leskovec. Qa-gnn:\\nReasoning with language models and knowledge graphs for question answering. In Proceedings\\nof the 2021 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, pp. 535–546, 2021.\\nWen-tau Yih, Matthew Richardson, Christopher Meek, Ming-Wei Chang, and Jina Suh. The value\\nof semantic parse labeling for knowledge base question answering. In Proceedings of the 54th\\nAnnual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pp.\\n201–206, 2016.\\nPing Yu, Tianlu Wang, Olga Golovneva, Badr AlKhamissi, Siddharth Verma, Zhijing Jin, Gargi\\nGhosh, Mona Diab, and Asli Celikyilmaz. Alert: Adapting language models to reasoning tasks.\\narXiv preprint arXiv:2212.08286, 2022.\\nJing Zhang, Xiaokang Zhang, Jifan Yu, Jian Tang, Jie Tang, Cuiping Li, and Hong Chen. Subgraph\\nretrieval enhanced model for multi-hop knowledge base question answering. In Proceedings of the\\n60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),\\npp. 5773–5784, 2022.\\nPeitian Zhang, Shitao Xiao, Zheng Liu, Zhicheng Dou, and Jian-Yun Nie. Retrieve anything to\\naugment large language models. arXiv preprint arXiv:2310.07554, 2023.\\n14\\nYuqi Zhu, Shuofei Qiao, Yixin Ou, Shumin Deng, Ningyu Zhang, Shiwei Lyu, Yue Shen, Lei Liang,\\nJinjie Gu, and Huajun Chen. Knowagent: Knowledge-augmented planning for llm-based agents.\\narXiv preprint arXiv:2403.03101, 2024.\\nAppendix\\nTable of Contents\\n7\\nDatasets\\n15\\n8\\nBaselines\\n16\\n9\\nImplementation Details and Experiment Settings\\n17\\n10 Additional Experiment Results\\n19\\n10.1 Performance on Different Hops . . . . . . . . . . . . . . . . . . . . . . . . . .\\n19\\n11 Templates and Prompts\\n19\\n7\\nDATASETS\\nKGQA Datasets. To compare the reasoning performance with existing methods, we use two bench-\\nmark KGQA datasets in this study: WebQuestionSP (WebQSP) (Yih et al., 2016) and Complex We-\\nbQuestions (CWQ) (Talmor & Berant, 2018). To ensure fairness, we adopt the same train and test\\nsplits as previous works (Jiang et al., 2022; Luo et al., 2024). Details of the datasets can be found in\\nTable 7.\\nBoth WebQSP and CWQ can be reasoned using Freebase KGs2 (Bollacker et al., 2008). To reduce\\nthe size of the KGs, we use a subgraph of Freebase by extracting all triples that start from question\\nentities within the maximum reasoning hops provided by previous works3 (Luo et al., 2024). The\\nstatistics of the knowledge graphs are shown in Table 9.\\nFine-tuning Datasets. To enhance the KG reasoning ability of LLMs, we construct fine-tuning\\ndatasets by generating reasoning paths from the KGs. Specifically, we adopt the training split of\\nWebQSP and CWQ, which contain 2,826 and 27,639 question-answer pairs, respectively. For each\\nquestion, we find all the shortest reasoning paths on KGs that connect the question entity to the\\nanswer entity. We then convert the reasoning paths into formatted strings and pair them with the\\nquestion-answer pairs with the template shown in Figure 8 to form the fine-tuning datasets. Since\\nthere could be multiple reasoning paths for a question, we generate multiple training instances paired\\nwith different reasoning paths for each question-answer pair. The fine-tuning datasets contain 28,307\\nand 181,602 question-reasoning path-answer triples for WebQSP and CWQ, respectively. The statis-\\ntics of the fine-tuning datasets are shown in Table 8.\\nZero-shot Generalization Datasets.\\nTo evaluate the transferability of GCR, we further select\\ntwo new KGQA datasets4: CommonsenseQA (CSQA) (Talmor et al., 2019) and MedQA-USMLE\\n(MedQA) (Jin et al., 2021). CSQA is a 5-way multiple choice QA dataset that involves reasoning\\nwith commonsense knowledge. MedQA is a 4-way multiple choice QA task that requires biomed-\\nical and clinical knowledge. For CSQA, we use the ConceptNet (Speer et al., 2017), which is a\\ngeneral-purpose KG that contains commonsense knowledge. For MedQA, we use a medical KG\\n2https://github.com/microsoft/FastRDFStore\\n3WebQSP: https://huggingface.co/datasets/rmanluo/RoG-webqsp, CWQ: https://\\nhuggingface.co/datasets/rmanluo/RoG-cwq\\n4https://github.com/michiyasunaga/qagnn\\n15\\nconstructed from the Unified Medical Language System (Yasunaga et al., 2021). The statistics of\\nthe knowledge graphs are shown in Table 9. We respectively select 100 questions from each dataset.\\nFor each question, following previous studies (Feng et al., 2020; Yasunaga et al., 2021), a 2-hop\\nsubgraph is extracted from the KGs to form the zero-shot generalization datasets.\\nTable 7: Statistics of datasets.\\nDataset\\nDataset Statistics\\nStatistics of Answer Numbers\\n#Train\\n#Test\\n#Ans = 1\\n2 ≥#Ans ≤4\\n5 ≥#Ans ≤9\\n#Ans ≥10\\nWebQSP\\n2,826\\n1,628\\n51.2%\\n27.4%\\n8.3%\\n12.1%\\nCWQ\\n27,639\\n3,531\\n70.6%\\n19.4%\\n6%\\n4%\\nTable 8: Statistics of fine-tuning datasets for graph-constrained decoding.\\nTotal\\nWebQSP\\nCWQ\\n209,909\\n28,307\\n181,602\\nTable 9: Statistics of constructed knowledge graphs.\\nKG\\n#Entities\\n#Relations\\n#Triples\\nFreebase\\n2,566,291\\n7,058\\n8,309,195\\nConceptNet\\n799,273\\n17\\n2,151,303\\nMedKG\\n9,958\\n15\\n49,974\\n8\\nBASELINES\\nWe compare GCR with the 22 baselines grouped into three categories: 1) LLM reasoning methods,\\n2) graph reasoning methods, and 3) KG-enhanced LLM reasoning methods. The details of each\\nbaseline are described as follows.\\nLLM reasoning methods only rely on LLMs for reasoning without utilizing external KGs. We\\ninclude both the vanilla LLMs with different sizes and the LLMs with advanced reasoning mecha-\\nnisms. Specifically, we consider the following baselines:\\n• Qwen2-0.5B/1.5B.7B (Yang et al., 2024a) provides a series of pre-trained LLMs with dif-\\nferent sizes, including 0.5B, 1.5B, and 7B parameters.\\n• Llama-2-7B (Touvron et al., 2023) is a large-scale LLM pre-trained on a diverse range of\\ntasks.\\n• Llama-3.1-8B (Meta, 2024) is the updated version of Llama-2 with more powerful reason-\\ning capabilities.\\n• ChatGPT (OpenAI, 2022) is a powerful closed-source LLM that could follow instructions\\nto conduct complex tasks.\\n• GPT-4o-mini (OpenAI, 2024a) is the new flagship model of OpenAI that could reason\\nacross different modalities and tasks.\\n• Few-shot prompt (Brown et al., 2020) is a few-shot learning method that provides LLMs\\nwith a few examples in the prompts to conduct reasoning.\\n• CoT (Wei et al., 2022) is a chain-of-thought reasoning method that prompts LLMs to gen-\\nerate a chain of reasoning steps.\\n• Self-consistency (Wang et al., 2024) generates multiple reasoning paths and selects the\\nmost consistent answer.\\n16\\nGraph reasoning methods focus on reasoning on KGs using graph neural networks (GNNs) (Wu\\net al., 2020) or graph-based reasoning mechanisms. We include the following baselines:\\n• GraftNet (Sun et al., 2018) is a graph-based reasoning method that retrieves relevant sub-\\ngraphs from KGs with entity linking.\\n• NSM (He et al., 2021) utilizes the sequential model to mimic the multi-hop reasoning\\nprocess on KGs.\\n• SR+NSM (Zhang et al., 2022) proposes a relation-path retrieval to retrieve subgraphs for\\nmulti-hop reasoning.\\n• ReaRev (Mavromatis & Karypis, 2022) is a GNN-based method that reasons on KGs by\\nconsidering complex graph information.\\nKG-enhanced LLM reasoning methods incorporate KGs to enhance the reasoning abilities of\\nLLMs which can be further divided into retrieval-based and agent-based paradigms. We include the\\nfollowing baselines:\\nRetrieval-based methods retrieve relevant facts from KGs with an external retriever and then feed\\nthem into the inputs of LLMs for reasoning:\\n• KD-CoT (Wang et al., 2023) retrieves relevant knowledge from KGs to generate faithful\\nreasoning plans for LLMs.\\n• EWEK-QA (Dehghan et al., 2024) enriches the retrieved knowledge by searching from\\nboth KGs and web.\\n• RoG (Luo et al., 2024) proposes a planning-retrieval-reasoning framework that retrieves\\nreasoning paths from KGs to guide LLMs conducting faithful reasoning.\\n• GNN-RAG (Mavromatis & Karypis, 2024) adopts a lightweight graph neural network to\\neffectively retrieve from KGs.\\n• GNN-RAG+RA (Mavromatis & Karypis, 2024) combines the retrieval results of both RoG\\nand GNN-RAG to enhance the reasoning performance.\\nAgent-based methods treat LLMs as agents that iteratively interact with KGs to find reasoning paths\\nand answers:\\n• ToG (Sun et al., 2024) conducts the reasoning on KGs by exploring multiple paths and\\nconcludes the final answer by aggregating the evidence from them.\\n• EffiQA (Jiang et al., 2024) proposes an efficient agent-based method to reason on KGs.\\n9\\nIMPLEMENTATION DETAILS AND EXPERIMENT SETTINGS\\nIn this section, we will detail the implementation of GCR as well as the experiment settings.\\nFine-tuning KG-specialized LLMs. We fine-tune several lightweight LLMs ranging from 0.5B to\\n8B (Yang et al., 2024a; Touvron et al., 2023; Meta, 2024) on the fine-tuning datasets for 3 epochs.\\nThe batch size is set to 4 and the learning rate is set to 2e-5. We use the cosine learning rate scheduler\\npolicy with the warmup ratio set to 0.03. The training is conducted on 2 A100-80G GPUs for each\\nmodel. The training time and memory usage are shown in Table 10.\\nKGQA Experiment Settings. The KGQA experiment shown in Table 1 aims to compare the rea-\\nsoning performance of GCR with existing methods. For our method, we use the fine-tuned Llama-\\n3.1-8B as KG-specialized LLMs, the general LLM is selected as ChatGPT and GPT-4o-mini. The\\nKG-Trie is constructed from the subgraph of Freebase KGs. The maximum reasoning hops are set\\nto 2 for both WebQSP and CWQ. The beam size is set to 10 for graph-constrained decoding. For\\nvanilla LLMs baselines, we use the zero-shot prompting to ask the models to answer the questions.\\nFor other baselines, we strictly check whether the original papers follow the same settings and copy\\nthe results for fair comparison.\\nEfficiency Analysis Settings. The efficiency analysis shown in Table 2 aims to compare the effi-\\nciency and performance of different methods on WebQSP. For GCR, we use the same settings as the\\n17\\nTable 10: Training time and memory usage for different KG-specialized LLMs.\\nModel\\nTime\\nMem. Usage per GPU\\nQwen2-0.5B\\n3.47h\\n10G\\nQwen2-1.5B\\n4.11h\\n25G\\nQwen2-7B\\n14.37h\\n81G\\nLlama-2-7B\\n13.93h\\n80G\\nLlama-3.1-8B\\n14.52h\\n85G\\nKGQA experiment. For dense retriever methods (e.g., S-Bert (Reimers & Gurevych, 2019), BGE\\n(Zhang et al., 2023), OpenAI-Emb. (OpenAI, 2024b)), we first search all paths within 2-hops on the\\nKGs which are formatted as sentences with the template in Figure 7. Then, we adopt the embedding\\nmodel to encode the path sentences as embeddings which are stored in a vector database. During in-\\nference, we retrieve 10 paths from the vector database with the question as query and feed them into\\nthe LLMs for reasoning. For GNN-RAG (Mavromatis & Karypis, 2024) and RoG (Luo et al., 2024),\\nwe strictly follow the original papers to retrieve reasoning paths and conduct the experiments. For\\nagent-based methods (e.g., ToG (Sun et al., 2024)), we use the same settings detailed in the original\\npapers. For EffiQA (Jiang et al., 2024), since there is no available code, we directly copy the results\\nfrom the original paper.\\nThe average runtime is measured by the time taken to answer the questions. The average number\\nof LLM calls is the number of times the LLMs are called to answer the questions. The average\\nnumber of LLM tokens is the number of tokens inputted into LLMs to answer the questions, such\\nas questions and retrieved reasoning paths. The experiments are conducted on a single A100-80G\\nGPU for each method.\\nAblation Study. In ablation study, we first try to analyze the effectiveness of different components in\\nGCR. We conduct the experiments on WebQSP and CWQ datasets. By removing the KG-specialized\\nLLM (w/o KG-specialized LLM), we search all the 2-hop paths starting from question entities and\\nfeed them into the general LLMs for reasoning. By removing the general LLM (w/o general LLM),\\nwe directly use the hypothesis answers generated by the KG-specialized LLMs as the final answers.\\nDifferent LLMs. We also analyze the different LLMs used for KG-specialized LLMs and general\\nLLMs on WebQSP. For KG-specialized LLMs, we first use the vanilla LLMs with different learning\\ntypes (i.e., zero-shot and few-shot prompting). For zero-shot prompting, we directly ask the models\\nto generate the reasoning paths with the constraints. For few-shot prompting, we provide the models\\nwith a few examples in the prompts to conduct path generation. Detailed prompts can be found in\\nFigures 8 and 10. Then, we fine-tune the lightweight LLMs with different sizes (0.5B to 8B) on the\\ngraph-constrained decoding task. For general LLMs, we use the vanilla LLMs to directly conduct\\nreasoning over multiple reasoning paths. The detailed reasoning prompts can be found in Figure 9.\\nParameter Analysis. We first analyze the performance of GCR with different beam sizes for graph-\\nconstrained decoding. We conduct the experiments on the WebQSP datasets with beam sizes of 1, 3,\\n5, 10, and 20. Then, we analyze the performance of GCR with different hops of paths encoded in the\\nKG-Trie. We conduct the experiments on the WebQSP datasets with maximum paths hops ranging\\nfrom 1 to 4.\\nFaithful Reasoning Analysis. We investigate the effect of the KG constraints on ensuring faithful\\nreasoning. We adopt the fine-tuned Llama-3.1-8B as KG-specialized LLMs. Then, we compare\\nthe faithful reasoning rate and answer hit of GCR with and without the KG constraints in graph-\\nconstrained decoding. The faithful reasoning rate is the percentage of the faithful reasoning in the\\ncorrectly predicted answers. A reasoning path is considered faithful if it can be found in the KGs,\\nand vice versa. The answer hit is the percentage of the correct answers in the predictions.\\nZero-shot Generalization Analysis. We evaluate the transferability of GCR on two zero-shot gen-\\neralization datasets: CSQA and MedQA. We use the fine-tuned Llama-3.1-8B as KG-specialized\\nLLMs and ChatGPT as well as GPT-4o-mini as the general LLMs. The KG-Trie is constructed\\nfrom the subgraph of ConceptNet and MedKG. The maximum reasoning hops are set to 2 for both\\ndatasets. The beam size is set to 10 for graph-constrained decoding. For vanilla LLMs baselines\\n18\\n(i.e., ChatGPT and GPT-4o-mini), we use the zero-shot prompting to ask the models to answer the\\nquestions.\\n10\\nADDITIONAL EXPERIMENT RESULTS\\n10.1\\nPERFORMANCE ON DIFFERENT HOPS\\nIn this section, we analyze the impact of different hops of reasoning paths on the performance of\\nGCR. We conduct the experiments on WebQSP with different maximum hops of reasoning paths\\nencoded in the KG-Trie. The results are shown in Figure 6. We observe that the performance\\nof GCR increases with the number of hops of reasoning paths. The performance peaks when the\\nmaximum hops of reasoning paths are set to 2. This is because the 2-hop paths can provide sufficient\\ninformation for the LLMs to conduct reasoning. When the hops are set to 3 or 4, the performance\\ndrops due to the increased complexity of the reasoning paths, which may introduce noise and make\\nthe reasoning less reliable. Additionally, the size of the KG-Trie slightly increases from 0.5 MB to\\n7.5 MB with the increase of the hops from 1 to 4. This indicates that the KG-Trie can be efficiently\\nconstructed with a small size and guide the LLMs to reason on graphs effectively.\\n1\\n2\\n3\\n4\\nKG-Trie Path Length L\\n0\\n2\\n4\\n6\\nAvg. KG-Trie size (MB)\\n60\\n70\\n80\\n90\\nAnswer Coverage (%)\\nAvg. KG-Trie size (MB)\\nHit\\nF1\\nPrecision\\nRecall\\nFigure 6: Parameter analysis of path hop L for KG-Trie construction on WebQSP.\\n11\\nTEMPLATES AND PROMPTS\\nIn this section, we illustrate all the templates and prompts used in the experiments.\\nPath Sentence Template. The template for converting reasoning paths into natural language sen-\\ntences is shown in Figure 7, where the e∗and r∗denotes the entities and relations in a reasoning\\npath wz = e0\\nr1\\n−→e1\\nr2\\n−→. . .\\nrl\\n−→el,\\nPath Sentence Template\\n<PATH> e1 →r1 →e2 →. . . →rl →el </PATH>\\nFigure 7: The template for converting reasoning paths into formatted sentences.\\nGraph-constrained Decoding Prompt. The prompt for graph-constrained decoding is shown in\\nFigure 8, where the question and mentioned entities are provided to the LLMs to generate rea-\\nsoning paths and hypothesis answers. In the fine-tuning datasets, the supervised LLM outputs are\\nconstructed from the ground-truth answers and reasoning paths extracted from the KGs.\\n19\\nGraph-constrained Decoding Prompt\\n============================= Prompt Input ================================\\nReasoning path is a sequence of triples in the KG that connects the topic entities in the question to\\nanswer entities. Given a question, please generate some reasoning paths in the KG starting from the\\ntopic entities to answer the question.\\n# Question:\\n<Question>\\n# Topic entities:\\n<Question Entities>\\n============================= LLM Output ================================\\n# Reasoning Path:\\n<PATH> <Reasoning Path> </PATH>\\n# Answer:\\n<Hypothesis Answer>\\nFigure 8: The prompt template for graph-constrained decoding.\\nThe few-shot prompt template for graph-constrained decoding is shown in Figure 10. We provide a\\nfew examples in the prompts to guide the LLMs to generate reasoning paths. Since the LLMs with\\nfew-shot prompt learning are not fine-tuned on the graph-constrained decoding task, we only apply\\nthe constraint to generate reasoning paths.\\nGraph Inductive Reasoning Prompt. The prompt for graph inductive reasoning is shown in Fig-\\nure 9. We adopt the graph-constrained decoding to generate K reasoning paths and hypothesis\\nanswers for each question. The reasoning paths and hypothesis answers are provided to the general\\nLLMs to answer the questions without fine-tuning.\\nGraph Inductive Reasoning Prompt\\n============================= Prompt Input ================================\\n# Reasoning Paths:\\n<Reasoning Path 1><Hypothesis Answer 1>\\n. . .\\n<Reasoning Path K><Hypothesis Answer K>\\n# Question:\\n<Question>\\nBased on the reasoning paths, please answer the given question. Please keep the answer as simple as\\npossible and only return answers. Please return each answer in a new line.\\n============================= LLM Output ================================\\n<Answer 1>\\n<Answer 2>\\n. . .\\nFigure 9: The prompt template for graph inductive reasoning.\\n20\\nFew-shot Graph-constrained Decoding Prompt\\n============================= Prompt Input ================================\\nReasoning path is a sequence of triples in the KG that connects the topic entities in the question to\\nanswer entities. Given a question, please generate some reasoning paths in the KG starting from the\\ntopic entities to answer the question.\\nExample 1\\n# Question:\\n<Question>\\n# Topic entities:\\n<Question Entities>\\n# Reasoning Path:\\n<Reasoning Path>\\nExample 2\\n# Question:\\n<Question>\\n# Topic entities:\\n<Question Entities>\\n# Reasoning Path:\\n<Reasoning Path>\\nExample 3\\n# Question:\\n<Question>\\n# Topic entities:\\n<Question Entities>\\n# Reasoning Path:\\n<Reasoning Path>\\nInput\\n# Question:\\n<Question>\\n# Topic entities:\\n<Question Entities>\\n============================= LLM Output ================================\\n# Reasoning Path:\\n<Reasoning Path>\\nFigure 10: The few-shot prompt template for graph-constrained decoding.\\n21\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arxiv_documents[0].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "collapsed": true,
        "id": "r3_ON2kETs3i",
        "outputId": "280b4ebb-21f8-4d18-a409-8f689a8fc58f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Published': '2024-10-16', 'Title': 'Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models', 'Authors': 'Linhao Luo, Zicheng Zhao, Chen Gong, Gholamreza Haffari, Shirui Pan', 'Summary': 'Large language models (LLMs) have demonstrated impressive reasoning\\nabilities, but they still struggle with faithful reasoning due to knowledge\\ngaps and hallucinations. To address these issues, knowledge graphs (KGs) have\\nbeen utilized to enhance LLM reasoning through their structured knowledge.\\nHowever, existing KG-enhanced methods, either retrieval-based or agent-based,\\nencounter difficulties in accurately retrieving knowledge and efficiently\\ntraversing KGs at scale. In this work, we introduce graph-constrained reasoning\\n(GCR), a novel framework that bridges structured knowledge in KGs with\\nunstructured reasoning in LLMs. To eliminate hallucinations, GCR ensures\\nfaithful KG-grounded reasoning by integrating KG structure into the LLM\\ndecoding process through KG-Trie, a trie-based index that encodes KG reasoning\\npaths. KG-Trie constrains the decoding process, allowing LLMs to directly\\nreason on graphs and generate faithful reasoning paths grounded in KGs.\\nAdditionally, GCR leverages a lightweight KG-specialized LLM for\\ngraph-constrained reasoning alongside a powerful general LLM for inductive\\nreasoning over multiple reasoning paths, resulting in accurate reasoning with\\nzero reasoning hallucination. Extensive experiments on several KGQA benchmarks\\ndemonstrate that GCR achieves state-of-the-art performance and exhibits strong\\nzero-shot generalizability to unseen KGs without additional training.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Wikipedia loader\n",
        "from langchain_community.document_loaders import WikipediaLoader\n",
        "docs = WikipediaLoader(query=\"Generative AI\", load_max_docs=2).load()\n",
        "len(docs)\n",
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "1YkB3-cIUX4I",
        "outputId": "e681b4a3-dfcb-4aea-a19b-ece6f428460d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'title': 'Generative artificial intelligence', 'summary': 'Generative artificial intelligence (generative AI, GenAI, or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.  \\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs. Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'}, page_content='Generative artificial intelligence (generative AI, GenAI, or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.  \\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs. Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.\\n\\n\\n== History ==\\n\\n\\n=== Early history ===\\nSince its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity. The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music. The tradition of creative automations has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.\\n\\n\\n=== Academic artificial intelligence ===\\nThe academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since. Artificial Intelligence research began in the 1950s with works like Computing Machinery and Intelligence (1950) and the 1956 Dartmouth Summer Research Project on AI. Since the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal. Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use, process plans for manufacturing and decision plans such as in prototype autonomous spacecraft.\\n\\n\\n=== Generative neural nets (2014-2019) ===\\n\\nSince its inception, the field of machine learning used both discriminative models and generative models, to mode'), Document(metadata={'title': 'AI boom', 'summary': 'The AI boom, or AI spring, is an ongoing period of rapid progress in the field of artificial intelligence (AI) that started in the late 2010s before gaining international prominence in the early 2020s. Examples include protein folding prediction led by Google DeepMind as well as large language models and generative AI applications developed by OpenAI.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/AI_boom'}, page_content='The AI boom, or AI spring, is an ongoing period of rapid progress in the field of artificial intelligence (AI) that started in the late 2010s before gaining international prominence in the early 2020s. Examples include protein folding prediction led by Google DeepMind as well as large language models and generative AI applications developed by OpenAI.\\n\\n\\n== History ==\\nIn 2012, a University of Toronto research team used artificial neural networks and deep learning techniques to lower the error rate below 25% for the first time during the ImageNet challenge for object recognition in computer vision. The event catalyzed the AI boom later that decade, when many alumni of the ImageNet challenge became leaders in the tech industry. In March 2016, AlphaGo beat Lee Sedol in a five-game match, marking the first time a computer Go program had beaten a 9-dan professional without handicap. This match led to significant increase in public interest in AI. The generative AI race began in earnest in 2016 or 2017 following the founding of OpenAI and earlier advances made in graphical processing units (GPUs), the amount and quality of training data, generative adversarial networks, diffusion models and transformer architectures. In 2018, the Artificial Intelligence Index, an initiative from Stanford University, reported a global explosion of commercial and research efforts in AI. Europe published the largest number of papers in the field that year, followed by China and North America. Technologies such as AlphaFold led to more accurate predictions of protein folding and improved the process of drug development. Economists and lawmakers began to discuss the potential impact of AI more frequently. By 2022, large language models (LLMs) saw increased usage in chatbot applications; text-to-image-models could generate images that appeared to be human-made; and speech synthesis software was able to replicate human speech efficiently.\\nAccording to metrics from 2017 to 2021, the United States outranks the rest of the world in terms of venture capital funding, the number of startups, and patents granted in AI. Scientists who have immigrated to the U.S. play an outsized role in the country\\'s development of AI technology. Many of them were educated in China, prompting debates about national security concerns amid worsening relations between the two countries.\\nExperts have framed AI development as a competition for economic and geopolitical advantage between the United States and China. In 2021, an analyst for the Council on Foreign Relations outlined ways that the U.S. could maintain its position amid progress made by China. In 2023, an analyst at the Center for Strategic and International Studies advocated for the U.S. to use its dominance in AI technology to drive its foreign policy instead of relying on trade agreements.\\n\\n\\n== Advances ==\\n\\n\\n=== Biomedical ===\\nThere have been proposals to use AI to advance radical forms of human life extension.\\nThe AlphaFold 2 score of more than 90 in CASP\\'s global distance test (GDT) is considered a significant achievement in computational biology and great progress towards a decades-old grand challenge of biology. Nobel Prize winner and structural biologist Venki Ramakrishnan called the result \"a stunning advance on the protein folding problem\", adding that \"It has occurred decades before many people in the field would have predicted.\"\\nThe ability to predict protein structures accurately based on the constituent amino acid sequence is expected to accelerate drug discovery and enable a better understanding of diseases. It went on to note that the AI algorithm could \"predict the shape of proteins to within the width of an atom.\"\\n\\n\\n=== Images and videos ===\\n\\nText-to-image models captured widespread public attention when OpenAI announced DALL-E, a transformer system, in January 2021. A successor capable of generating complex and realistic images, DALL-E 2, was unveiled in April 2022. An alternative text-to-image model, Midjo')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "nKTU5vDOU4gD",
        "outputId": "07cb58c1-c9a5-4f91-decf-06ae9dd1e841"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'Generative artificial intelligence', 'summary': 'Generative artificial intelligence (generative AI, GenAI, or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.  \\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs. Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'}\n"
          ]
        }
      ]
    }
  ]
}